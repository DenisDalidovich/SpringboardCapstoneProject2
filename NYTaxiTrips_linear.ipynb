{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modelling: Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will use Elastic Net Regression to predict the trip duration given the dataset prepared earlier. We use this type of regerssion because of its ability to combine Lasso and Ridge regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the garbage collection module\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610.96875"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the module that shows the memory usage\n",
    "\n",
    "import os, psutil\n",
    "\n",
    "def usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info()[0] / float(2 ** 20)\n",
    "    \n",
    "usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621.140625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modif = pd.read_csv('NYCTripDuration_modified.csv')\n",
    "usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the dataframe from the 'NYCTripDuration_modified.csv' file prepared earlier, we drop the 'Unnamed: 0' and 'effective_speed(kmph)' columns, and shuffle the dataframe arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599.01171875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_modif.columns\n",
    "df_modif = df_modif.drop(['Unnamed: 0','effective_speed(kmph)'], axis = 1)\n",
    "\n",
    "#df_modif.head()\n",
    "usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle the dataframe arbitrarily\n",
    "df_modif.sample(frac=1, random_state = 20).reset_index(drop=True, inplace = True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then write the function that calculates the accuracy of the predicted quantities. This function will be used to compute the accuracies of the predicted mean and standard deviation of the continuous target vafriable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accur_func(y_pred, y):\n",
    "    return 1.0 - (np.abs(y_pred - y)/np.abs(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we split the dataset into arrays of feature and target variables, and create the list of column names. There are 1450573 instances at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450573\n"
     ]
    }
   ],
   "source": [
    "X = df_modif.drop('trip_duration(hrs)', axis = 1).values\n",
    "\n",
    "y = df_modif['trip_duration(hrs)'].values\n",
    "\n",
    "# create the list containing the relevant columns\n",
    "column_names = df_modif.drop('trip_duration(hrs)',axis =1).columns.values\n",
    "\n",
    "n_instances = len(y)\n",
    "print(n_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running ElasticNet Regression on the original dataset (with the values alpha = 0.01 and l1_ratio = 0.5), we obtain miserable results. Not only the coefficient of determination is low (0.527), the accuracy of prediction of the standard deviation for the target variable is also low (72.03 percent) (although mean was predicted well enough). This is due to the fact that this method is very susceptible to outliers. Indeed, the target variable 'trip_duration(hrs)', as well as on of the feature variables 'geographical_dist(km)' are very broadly distributed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.482870812746\n",
      "Test score: 0.527476050547\n",
      "\n",
      "\n",
      "Actual mean of the test set: 0.233571084792\n",
      "Predicted mean of the test set: 0.233850228374\n",
      "Accuracy of prediction of the mean: 0.998804888105\n",
      "\n",
      "\n",
      "Actual std of the test set: 0.195445086378\n",
      "Predicted std of the test set: 0.140797277942\n",
      "Accuracy of prediction of the std: 0.720393029833\n",
      "\n",
      "\n",
      "Wall time: 4.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "elnetreg = ElasticNet(alpha=0.01, l1_ratio=0.5, random_state=50, selection='random')\n",
    "\n",
    "#X =  StandardScaler().fit_transform(X)\n",
    "#y =  StandardScaler().fit_transform(y)\n",
    "\n",
    "#adding polynomial features\n",
    "#X = PolynomialFeatures().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 45, \n",
    "                                                    stratify = None)\n",
    "\n",
    "elnetreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = elnetreg.predict(X_train)\n",
    "y_test_pred = elnetreg.predict(X_test)\n",
    "\n",
    "elnetreg_training_score = elnetreg.score(X_train, y_train)\n",
    "elnetreg_test_score = elnetreg.score(X_test, y_test)\n",
    "\n",
    "y_test_mean_elnet =  y_test.mean()\n",
    "y_test_pred_mean_elnet =  y_test_pred.mean()\n",
    "y_test_mean_accur_elnet = accur_func(y_test_pred_mean_elnet, y_test_mean_elnet)\n",
    "\n",
    "y_test_std_elnet =  y_test.std()\n",
    "y_test_pred_std_elnet =  y_test_pred.std()\n",
    "y_test_std_accur_elnet = accur_func(y_test_pred_std_elnet, y_test_std_elnet)\n",
    "\n",
    "print('Training score:', elnetreg_training_score)\n",
    "print('Test score:', elnetreg_test_score)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual mean of the test set:', y_test_mean_elnet)\n",
    "print('Predicted mean of the test set:', y_test_pred_mean_elnet)\n",
    "print('Accuracy of prediction of the mean:', y_test_mean_accur_elnet)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual std of the test set:', y_test_std_elnet)\n",
    "print('Predicted std of the test set:', y_test_pred_std_elnet)\n",
    "print('Accuracy of prediction of the std:', y_test_std_accur_elnet)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.31640625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X, y, X_train, X_test, y_train, y_test)\n",
    "gc.collect()\n",
    "\n",
    "usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to improve the accuracy of predictions by truncating our dataset. Namely, let's remove the instances where 'geographical_dist(km)' is greater than 60 km and those that last more than 6 hours. \n",
    "\n",
    "Once the dataset is truncated, we run Elastic Net once again using 3-fold cross-validation to determine the optimal values of parameters alpha (possible values are 0.0001, 0.001, 0.01 and 0.1) and l1_ratio (possible values are 0.1, 0.3 and 0.8). We see that the accuracy of the model has increased considerably; the test score is 0.597, while the mean and std of the target variable are predicted with accuracy 99.93 and 77.31 percent respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_modif = df_modif[(df_modif['geographical_dist(km)'] < 60) & \\\n",
    "                    (df_modif['trip_duration(hrs)'] < 6)]\n",
    "\n",
    "X = df_modif.drop('trip_duration(hrs)', axis = 1).values\n",
    "\n",
    "y = df_modif['trip_duration(hrs)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of best parameters are: {'alpha': 0.0001, 'l1_ratio': 0.1}\n",
      "Training score: 0.598602025012\n",
      "Test score: 0.596641050462\n",
      "\n",
      "\n",
      "Actual mean of the test set: 0.232793845736\n",
      "Predicted mean of the test set: 0.232950521004\n",
      "Accuracy of prediction of the mean: 0.999326978479\n",
      "\n",
      "\n",
      "Actual std of the test set: 0.18405219248\n",
      "Predicted std of the test set: 0.142300756827\n",
      "Accuracy of prediction of the std: 0.773154369475\n",
      "\n",
      "\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "elnetreg = ElasticNet(random_state=50, selection='random')\n",
    "\n",
    "# use the StandardScaler\n",
    "X =  StandardScaler().fit_transform(X)\n",
    "scaler = StandardScaler().fit(y)\n",
    "y =  scaler.transform(y)\n",
    "\n",
    "#adding polynomial features\n",
    "#X = PolynomialFeatures().fit_transform(X)\n",
    "\n",
    "# parameters fitted during cross-validation\n",
    "params = {\"alpha\": [0.0001, 0.001, 0.01, 0.1], \"l1_ratio\": [0.1, 0.3, 0.8]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 45, \n",
    "                                                    stratify = None)\n",
    "\n",
    "cv_elnetreg = GridSearchCV(elnetreg, param_grid = params, cv = 3)\n",
    "cv_elnetreg.fit(X_train, y_train)\n",
    "\n",
    "print('The value of best parameters are:',cv_elnetreg.best_params_)\n",
    "\n",
    "\n",
    "y_train_pred = cv_elnetreg.predict(X_train)\n",
    "y_test_pred = cv_elnetreg.predict(X_test)\n",
    "\n",
    "# compute the coefficients of determination\n",
    "elnetreg_training_score = cv_elnetreg.score(X_train, y_train)\n",
    "elnetreg_test_score = cv_elnetreg.score(X_test, y_test)\n",
    "\n",
    "#scale back the target variable\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "y_test_mean_elnet =  y_test.mean()\n",
    "y_test_pred_mean_elnet =  y_test_pred.mean()\n",
    "y_test_mean_accur_elnet = accur_func(y_test_pred_mean_elnet, y_test_mean_elnet)\n",
    "\n",
    "y_test_std_elnet =  y_test.std()\n",
    "y_test_pred_std_elnet =  y_test_pred.std()\n",
    "y_test_std_accur_elnet = accur_func(y_test_pred_std_elnet, y_test_std_elnet)\n",
    "\n",
    "print('Training score:', elnetreg_training_score)\n",
    "print('Test score:', elnetreg_test_score)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual mean of the test set:', y_test_mean_elnet)\n",
    "print('Predicted mean of the test set:', y_test_pred_mean_elnet)\n",
    "print('Accuracy of prediction of the mean:', y_test_mean_accur_elnet)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual std of the test set:', y_test_std_elnet)\n",
    "print('Predicted std of the test set:', y_test_pred_std_elnet)\n",
    "print('Accuracy of prediction of the std:', y_test_std_accur_elnet)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the weights after running the regression. The most important feature (highest weight in absolute value) is 'geographical_dist(km)', as expected. The second and third most important features are 'dropoff_latitude' and 'dropoff_longitude' respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>ELNETREG_COEFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geographical_dist(km)</td>\n",
       "      <td>0.803694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pickup_month</td>\n",
       "      <td>0.046158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pickup_latitude</td>\n",
       "      <td>0.043823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.039277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pickup_day</td>\n",
       "      <td>0.007016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.006895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>store_and_fwd_flag</td>\n",
       "      <td>0.005766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vendor_id</td>\n",
       "      <td>-0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pickup_minute</td>\n",
       "      <td>-0.004201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pickup_longitude</td>\n",
       "      <td>-0.031822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pickup_day_of_week</td>\n",
       "      <td>-0.038226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dropoff_longitude</td>\n",
       "      <td>-0.052426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dropoff_latitude</td>\n",
       "      <td>-0.065097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              COLUMN_NAME  ELNETREG_COEFF\n",
       "0   geographical_dist(km)        0.803694\n",
       "1            pickup_month        0.046158\n",
       "2         pickup_latitude        0.043823\n",
       "3             pickup_hour        0.039277\n",
       "4              pickup_day        0.007016\n",
       "5         passenger_count        0.006895\n",
       "6      store_and_fwd_flag        0.005766\n",
       "7               vendor_id       -0.000806\n",
       "8           pickup_minute       -0.004201\n",
       "9        pickup_longitude       -0.031822\n",
       "10     pickup_day_of_week       -0.038226\n",
       "11      dropoff_longitude       -0.052426\n",
       "12       dropoff_latitude       -0.065097"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the coefficients\n",
    "\n",
    "elnetreg_coeff = ElasticNet(alpha = cv_elnetreg.best_params_['alpha'],\n",
    "                            l1_ratio = cv_elnetreg.best_params_['l1_ratio'],\n",
    "    random_state=50, selection='random').fit(X_train, y_train).coef_\n",
    "\n",
    "\n",
    "df_elnetreg_coeff = pd.DataFrame(column_names, columns = ['COLUMN_NAME'])\n",
    "df_elnetreg_coeff['ELNETREG_COEFF'] = np.transpose(elnetreg_coeff)\n",
    "\n",
    "df_elnetreg_coeff.sort_values('ELNETREG_COEFF', ascending = False, inplace = True)\n",
    "df_elnetreg_coeff.reset_index(drop = True, inplace = True)\n",
    "\n",
    "writer1 = pd.ExcelWriter('elnetreg_features.xlsx')\n",
    "df_elnetreg_coeff.to_excel(writer1)\n",
    "writer1.save()\n",
    "\n",
    "df_elnetreg_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302.265625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X, y, X_train, X_test, y_train, y_test)\n",
    "gc.collect()\n",
    "usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to improve the accuracy, let's drop the least important features: 'pickup_day', 'passenger_count', 'store_and_fwd_flag' \t'vendor_id' and 'pickup_minute', and use the PolynomialFeatures() to generate the squared number of the remaining features. We use the parameters alpha = 0.0001 and l1_ratio = 0.1. We see that the accuracy has increased although not as much as we hoped; the test score is 0.649, while the mean and std of the target variable are predicted with accuracy 99.91 and 80.72 percent respectively. This level of accuracy can hardly be regarded acceptable. It is possible that the accuracy can be improved further by generating cubic interactions between the features. However, this approach would require large computational resources, and we think it is better to try other methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_modif = df_modif.drop(['pickup_day', 'passenger_count', 'store_and_fwd_flag',\n",
    "                          'vendor_id','pickup_minute'], axis =1)\n",
    "\n",
    "\n",
    "X = df_modif.drop('trip_duration(hrs)', axis = 1).values\n",
    "\n",
    "y = df_modif['trip_duration(hrs)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.651995467025\n",
      "Test score: 0.64910691301\n",
      "\n",
      "\n",
      "Actual mean of the test set: 0.232793845736\n",
      "Predicted mean of the test set: 0.232984344321\n",
      "Accuracy of prediction of the mean: 0.999181685477\n",
      "\n",
      "\n",
      "Actual std of the test set: 0.18405219248\n",
      "Predicted std of the test set: 0.148579306352\n",
      "Accuracy of prediction of the std: 0.807267244959\n",
      "\n",
      "\n",
      "Wall time: 10min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "elnetreg = ElasticNet(alpha=0.0001, l1_ratio=0.1, random_state=50, selection='random')\n",
    "\n",
    "#adding polynomial features\n",
    "X = PolynomialFeatures().fit_transform(X)\n",
    "\n",
    "#doing the scaling\n",
    "X =  StandardScaler().fit_transform(X)\n",
    "scaler = StandardScaler().fit(y)\n",
    "y =  scaler.transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 45, \n",
    "                                                    stratify = None)\n",
    "\n",
    "elnetreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = elnetreg.predict(X_train)\n",
    "y_test_pred = elnetreg.predict(X_test)\n",
    "\n",
    "elnetreg_training_score = elnetreg.score(X_train, y_train)\n",
    "elnetreg_test_score = elnetreg.score(X_test, y_test)\n",
    "\n",
    "#scale back the target variable\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "y_test_mean_elnet =  y_test.mean()\n",
    "y_test_pred_mean_elnet =  y_test_pred.mean()\n",
    "y_test_mean_accur_elnet = accur_func(y_test_pred_mean_elnet, y_test_mean_elnet)\n",
    "\n",
    "y_test_std_elnet =  y_test.std()\n",
    "y_test_pred_std_elnet =  y_test_pred.std()\n",
    "y_test_std_accur_elnet = accur_func(y_test_pred_std_elnet, y_test_std_elnet)\n",
    "\n",
    "print('Training score:', elnetreg_training_score)\n",
    "print('Test score:', elnetreg_test_score)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual mean of the test set:', y_test_mean_elnet)\n",
    "print('Predicted mean of the test set:', y_test_pred_mean_elnet)\n",
    "print('Accuracy of prediction of the mean:', y_test_mean_accur_elnet)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual std of the test set:', y_test_std_elnet)\n",
    "print('Predicted std of the test set:', y_test_pred_std_elnet)\n",
    "print('Accuracy of prediction of the std:', y_test_std_accur_elnet)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.0546875"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X, y, X_train, X_test, y_train, y_test)\n",
    "gc.collect()\n",
    "usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modelling: Stochastic Gradient Decsent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will use Stochastic Gradient Descent Regression to make the prediction of the trip duration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280.3671875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modif = pd.read_csv('NYCTripDuration_modified.csv')\n",
    "\n",
    "df_modif = df_modif.drop(['Unnamed: 0','effective_speed(kmph)'], axis = 1)\n",
    "\n",
    "df_modif.sample(frac=1, random_state = 20).reset_index(drop=True, inplace = True)\n",
    "\n",
    "gc.collect()\n",
    "usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_modif = df_modif[(df_modif['geographical_dist(km)'] < 60) & \\\n",
    "                    (df_modif['trip_duration(hrs)'] < 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_modif.drop('trip_duration(hrs)', axis = 1).values\n",
    "\n",
    "y = df_modif['trip_duration(hrs)'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the Stochastic Gradient Descent regression with the optimal (not constant) learning rate, and use 3-fold cross-validation to determine the best values of parameters alpha (possible values are 0.0001, 0.001, 0.01, 0.1 and 1.0) and l1_ratio (possible values are 0.1, 0.3 and 0.8). We see that the accuracy of the model is not very high; the test score is 0.596, while the mean and std of the target variable are predicted with accuracy 99.82 and 75.47 percent respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of best parameters are: {'alpha': 0.01, 'l1_ratio': 0.1}\n",
      "Training score: 0.598166445123\n",
      "Test score: 0.596248681381\n",
      "\n",
      "\n",
      "Actual mean of the test set: 0.232793845736\n",
      "Predicted mean of the test set: 0.232380234738\n",
      "Accuracy of prediction of the mean: 0.998223273488\n",
      "\n",
      "\n",
      "Actual std of the test set: 0.18405219248\n",
      "Predicted std of the test set: 0.138914834759\n",
      "Accuracy of prediction of the std: 0.754757837369\n",
      "\n",
      "\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sgdreg = SGDRegressor(learning_rate = \"optimal\", random_state=50, \n",
    "                      eta0 = 0.01, penalty = \"elasticnet\")\n",
    "\n",
    "\n",
    "# use the StandardScaler\n",
    "X =  StandardScaler().fit_transform(X)\n",
    "scaler = StandardScaler().fit(y)\n",
    "y =  scaler.transform(y)\n",
    "\n",
    "#adding polynomial features\n",
    "#X = PolynomialFeatures(2).fit_transform(X)\n",
    "\n",
    "# parameters fitted during cross-validation\n",
    "params = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1.0], \"l1_ratio\": [0.1, 0.3, 0.8]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 45, \n",
    "                                                    stratify = None)\n",
    "\n",
    "cv_sgdreg = GridSearchCV(sgdreg, param_grid = params, cv = 3)\n",
    "cv_sgdreg.fit(X_train, y_train)\n",
    "\n",
    "print('The value of best parameters are:',cv_sgdreg.best_params_)\n",
    "\n",
    "y_train_pred = cv_sgdreg.predict(X_train)\n",
    "y_test_pred = cv_sgdreg.predict(X_test)\n",
    "\n",
    "# compute the coefficients of determination\n",
    "sgdreg_training_score = cv_sgdreg.score(X_train, y_train)\n",
    "sgdreg_test_score = cv_sgdreg.score(X_test, y_test)\n",
    "\n",
    "#scale back the target variable\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "y_test_mean_sgd =  y_test.mean()\n",
    "y_test_pred_mean_sgd =  y_test_pred.mean()\n",
    "y_test_mean_accur_sgd = accur_func(y_test_pred_mean_sgd, y_test_mean_sgd)\n",
    "\n",
    "y_test_std_sgd =  y_test.std()\n",
    "y_test_pred_std_sgd =  y_test_pred.std()\n",
    "y_test_std_accur_sgd = accur_func(y_test_pred_std_sgd, y_test_std_sgd)\n",
    "\n",
    "print('Training score:', sgdreg_training_score)\n",
    "print('Test score:', sgdreg_test_score)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual mean of the test set:', y_test_mean_sgd)\n",
    "print('Predicted mean of the test set:', y_test_pred_mean_sgd)\n",
    "print('Accuracy of prediction of the mean:', y_test_mean_accur_sgd)\n",
    "\n",
    "print('\\n')\n",
    "print('Actual std of the test set:', y_test_std_sgd)\n",
    "print('Predicted std of the test set:', y_test_pred_std_sgd)\n",
    "print('Accuracy of prediction of the std:', y_test_std_accur_sgd)\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of linear regression, most important feature is 'geographical_dist(km)', as expected. The second and third most important features are 'dropoff_latitude' and 'dropoff_longitude' respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>SGDREG_COEFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geographical_dist(km)</td>\n",
       "      <td>0.780251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pickup_month</td>\n",
       "      <td>0.042058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.039743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pickup_latitude</td>\n",
       "      <td>0.036967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.005884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pickup_day</td>\n",
       "      <td>0.005792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>store_and_fwd_flag</td>\n",
       "      <td>0.003663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vendor_id</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pickup_minute</td>\n",
       "      <td>-0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pickup_longitude</td>\n",
       "      <td>-0.024414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pickup_day_of_week</td>\n",
       "      <td>-0.038674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dropoff_longitude</td>\n",
       "      <td>-0.050904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dropoff_latitude</td>\n",
       "      <td>-0.061415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              COLUMN_NAME  SGDREG_COEFF\n",
       "0   geographical_dist(km)      0.780251\n",
       "1            pickup_month      0.042058\n",
       "2             pickup_hour      0.039743\n",
       "3         pickup_latitude      0.036967\n",
       "4         passenger_count      0.005884\n",
       "5              pickup_day      0.005792\n",
       "6      store_and_fwd_flag      0.003663\n",
       "7               vendor_id      0.000000\n",
       "8           pickup_minute     -0.005859\n",
       "9        pickup_longitude     -0.024414\n",
       "10     pickup_day_of_week     -0.038674\n",
       "11      dropoff_longitude     -0.050904\n",
       "12       dropoff_latitude     -0.061415"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the coefficients\n",
    "\n",
    "sgdreg_coeff = SGDRegressor(alpha = cv_sgdreg.best_params_['alpha'],\n",
    "                            l1_ratio = cv_sgdreg.best_params_['l1_ratio'],\n",
    "                     learning_rate = \"optimal\", random_state=50, \n",
    "                      eta0 = 0.1, penalty = \"elasticnet\").fit(X_train, y_train).coef_\n",
    "\n",
    "\n",
    "df_sgdreg_coeff = pd.DataFrame(column_names, columns = ['COLUMN_NAME'])\n",
    "df_sgdreg_coeff['SGDREG_COEFF'] = np.transpose(sgdreg_coeff)\n",
    "\n",
    "df_sgdreg_coeff.sort_values('SGDREG_COEFF', ascending = False, inplace = True)\n",
    "df_sgdreg_coeff.reset_index(drop = True, inplace = True)\n",
    "\n",
    "writer14 = pd.ExcelWriter('sgdreg_features.xlsx')\n",
    "df_sgdreg_coeff.to_excel(writer14)\n",
    "writer14.save()\n",
    "\n",
    "df_sgdreg_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283.65625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(X, y, X_train, X_test, y_train, y_test)\n",
    "gc.collect()\n",
    "usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Trying to improve the accuracy, we attempted to drop the least important features: 'pickup_day', 'passenger_count', 'store_and_fwd_flag', 'vendor_id' and 'pickup_minute', and use the PolynomialFeatures() to generate the squared number of the remaining features. However, doing this resulted in the learning procedure picking up unstable solution. We also even tried to go to cubic interaction and run the SGD regressor on smaller dataset due to memory constraint; the result was the same -- conversgence to wrong solution resulting in negative coefficient of dtermination.\n",
    "Thus, we abandon attempts to improve the accuracy further using SGD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of two methods are summarized in the table below. The conclusion one can make looking at the results is that it is better to use the nonlinear methods in an attempt to improve the accuracy of predictions. So, let's consider the Decision Tree and Random Forest regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>Elastic Net</th>\n",
       "      <th>Stochastic Grad. Descent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training score</td>\n",
       "      <td>0.651995</td>\n",
       "      <td>0.598166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test score</td>\n",
       "      <td>0.649107</td>\n",
       "      <td>0.596249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actual mean of the test set</td>\n",
       "      <td>0.232794</td>\n",
       "      <td>0.232794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Predicted mean of the test set</td>\n",
       "      <td>0.232984</td>\n",
       "      <td>0.232380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accuracy of prediction of the mean</td>\n",
       "      <td>0.999182</td>\n",
       "      <td>0.998223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Actual std of the test set</td>\n",
       "      <td>0.184052</td>\n",
       "      <td>0.184052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Predicted std of the test set</td>\n",
       "      <td>0.148579</td>\n",
       "      <td>0.138915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Accuracy of prediction of the std</td>\n",
       "      <td>0.807267</td>\n",
       "      <td>0.754758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Characteristics  Elastic Net  Stochastic Grad. Descent\n",
       "0                      Training score     0.651995                  0.598166\n",
       "1                          Test score     0.649107                  0.596249\n",
       "2         Actual mean of the test set     0.232794                  0.232794\n",
       "3      Predicted mean of the test set     0.232984                  0.232380\n",
       "4  Accuracy of prediction of the mean     0.999182                  0.998223\n",
       "5          Actual std of the test set     0.184052                  0.184052\n",
       "6       Predicted std of the test set     0.148579                  0.138915\n",
       "7   Accuracy of prediction of the std     0.807267                  0.754758"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charac = ['Training score', 'Test score', 'Actual mean of the test set',\n",
    "         'Predicted mean of the test set', 'Accuracy of prediction of the mean',\n",
    "         'Actual std of the test set', 'Predicted std of the test set', \n",
    "          'Accuracy of prediction of the std']\n",
    "\n",
    "values_elnet = [elnetreg_training_score, elnetreg_test_score, y_test_mean_elnet, \n",
    "                y_test_pred_mean_elnet,\n",
    "             y_test_mean_accur_elnet, y_test_std_elnet,\n",
    "             y_test_pred_std_elnet, y_test_std_accur_elnet ]\n",
    "\n",
    "values_sgd = [sgdreg_training_score, sgdreg_test_score, y_test_mean_sgd, y_test_pred_mean_sgd,\n",
    "             y_test_mean_accur_sgd, y_test_std_sgd,\n",
    "             y_test_pred_std_sgd, y_test_std_accur_sgd ]\n",
    "\n",
    "comptable_linear = pd.DataFrame({'Characteristics': charac, 'Elastic Net': values_elnet, \n",
    "                                'Stochastic Grad. Descent': values_sgd})\n",
    "\n",
    "\n",
    "writer26 = pd.ExcelWriter('comptable_linear.xlsx')\n",
    "comptable_linear.to_excel(writer26)\n",
    "writer26.save()\n",
    "\n",
    "comptable_linear.to_csv('comptable_linear.csv')\n",
    "\n",
    "comptable_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Time to execute the program is 17.46738317410151 minutes ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Time to execute the program is {} minutes ---\".format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
